
---
title: "Final Project Script"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
toc_depth: 3
date: "2024-11-21"
editor_options: 
  chunk_output_type: console
---

# Set-up and load data
```{r setup}
# Clear workspace of all objects and unload non-base packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE)
    )
}

# Load or install 'pacman' for package management
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {
    install.packages("pacman", repos = my_repo)
}

# **SPH server**: need to install rnaturalearthhires like so on the SPH server
if (!require("rnaturalearthhires")) {
    install.packages("rnaturalearthhires", repos = "https://ropensci.r-universe.dev", type = "source")
}

pacman::p_load(
    tidyverse,                 # Data manipulation and visualization
    # takes a while to install on SPH
    ggspatial,                 # Geospatial extensions for ggplot.  
    maptiles, # maptiles and tmap libraries can be used instead of or in combination with ggplot + ggspatial. maptiles offers more tile-based map flexibility; ggspatial provides the ability to annotate maps easily; tmap offers both static and interactive maps that we won't review in this course. 
    terra, # alternative mapping with raster files
    
    # need for SPH server?
    prettymapr,
    
    rnaturalearth,             # Land features for map layers (remove water locations)
    rnaturalearthhires,        # High-resolution land features 
    sf,                        # Handling spatial objects (modern replacement for 'sp')
    knitr,                     # Formatting tables with kable()
    gstat,                     # Geostatistical methods (e.g., kriging)
    Hmisc,                     # Data description functions like describe()
    scales,                    # Color scale customization for ggplot
    akima,                     # Bivariate interpolation for irregular data
    downloader,                 # Downloading files over HTTP/HTTPS
    tigris
)

```

```{r load.data}

annual_data <- read_csv("annual_data_and_predictions.csv")

census_shapefile <- st_read("cb_2019_53_tract_500k.shp")

grid_covariates <- read_csv("dr0311_grid_covariates.csv")

mobile_covariates <- read_csv("dr0311_mobile_covariates.csv")

stop_data <- read_csv("stop_data.csv")

acs_race <- read_csv("ACS19_race.csv")

acs_ethnicity <- read_csv("ACS19_ethnicity.csv")

acs_language <- read_csv("ACS19_language.csv")

acs_median_income <- read_csv("ACS19_median_income.csv")

acs_poverty <- read_csv("ACS19_poverty.csv")
```

# Clean data

We selected only NO2 (no2) and PM2.5 (neph_bscat) variables from the stop data and the annual data. We obtained Census shapefile data from the Census Bureau's website for Washington, and only kept those within King, Snohomish, Pierce, and Kitsap counties (*might not need Kitsap but I didn't want to open the map to check*). We linked data using the 6-digit tract code.


```{r data.cleaning}
# annual data
#glimpse(annual_data)
table(annual_data$variable)

#create variable to differentiate between stop site and collocation site
annual_data <- annual_data %>% 
  mutate(SiteType = ifelse(grepl("MS", location), "stop site",
                       ifelse(grepl("MC", location), "collocation site", NA)))

# keep only NO2 and PM, get rid of annual variable since they are all mean_of_win_medians
annual_clean <- annual_data %>% 
  filter(variable == "no2" | variable == "pm2.5_ug_m3") %>%
  filter(SiteType == "stop site") %>% 
  select(-c(annual, SiteType))


# stop data
#create variable to differentiate between stop site and collocation site
stop_data <- stop_data %>% 
  mutate(SiteType = ifelse(grepl("MS", location), "stop site",
                       ifelse(grepl("MC", location), "collocation site", NA)))

stop_clean <- stop_data %>% 
  filter(variable == "no2" | variable == "neph_bscat") %>%
  filter(SiteType == "stop site") %>% 
  select(c(runname, time, location, stop_id, instrument_id, variable, mean_value, median_value))   

# Get location coordinates
stop_coords <- annual_clean %>% select(c("location", "longitude", "latitude")) %>%
  unique()

stop_clean <- stop_clean %>% 
  filter(median_value > 0) %>% # what are our thoughts on this? Thought: should we report how many this got rid of?
  mutate(log_mean = log(mean_value)) %>% 
  mutate(log_median = log(median_value)) %>% 
  filter(log_median > 0) %>% # and on this? 
  left_join(stop_coords)

# Generate NO2 specific dataset
no2_stop_clean <- stop_clean %>%
  filter(variable == "no2")

# Generate PM2.5 specific dataset
pm25_stop_clean <- stop_clean %>% 
  filter(variable == "neph_bscat")


# census data
#glimpse(census_shapefile)
table(census_shapefile$COUNTYFP) # there are 39 counties, we don't need them all 
# only keep King (033), Snohomish (061), Pierce (053), Kitsap (035)
# get rid of LSAD and STATEFP since they are all the same
census_clean <- census_shapefile %>%
  filter(COUNTYFP %in% c("033", "061", "053", "035")) %>%
  select(-c(LSAD,STATEFP)) %>% 
  st_as_sf()

# grid covar
#glimpse(grid_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
# log-transform distance covariates

grid_covar_clean <- grid_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key)))) %>%
  select(c(location_id, native_id, tract_key, m_to_a1, m_to_a2, m_to_a3, pop10_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000)) %>%
  mutate(log_m_to_a1 = log(m_to_a1), log_m_to_a2=log(m_to_a2), log_m_to_a3=log(m_to_a3),
         log_m_to_coast=log(m_to_coast), log_m_to_l_airp=log(m_to_l_airp), 
         log_m_to_comm=log(m_to_comm)) %>% 
  select(-c(m_to_a1,m_to_a2,m_to_a3,m_to_coast,m_to_l_airp,m_to_comm))

# mobile covar
#glimpse(mobile_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
mobile_covar_clean <- mobile_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key)))) %>%
  select(c(location_id, native_id, tract_key, TRACTCE, m_to_a1, m_to_a2, m_to_a3, pop10_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000)) %>%
  mutate(log_m_to_a1 = log(m_to_a1), log_m_to_a2=log(m_to_a2), log_m_to_a3=log(m_to_a3),
         log_m_to_coast=log(m_to_coast), log_m_to_l_airp=log(m_to_l_airp), 
         log_m_to_comm=log(m_to_comm)) %>% 
  select(-c(m_to_a1,m_to_a2,m_to_a3,m_to_coast,m_to_l_airp,m_to_comm))

# create dataset with stop and mobile data combined
stop_and_mobile <- merge(stop_clean, mobile_covar_clean,
                       by.x = "location", by.y = "native_id", 
                       all = FALSE)

# Join with census_clean
stop_mobile_census <- census_clean %>%
  inner_join(stop_and_mobile, by = "TRACTCE") %>% 
  select(c(TRACTCE, location, time, variable, mean_value, median_value, pop10_s05000, lu_industrial_p03000, log_m_to_a1, log_m_to_a2, log_m_to_a3, log_m_to_coast, log_m_to_l_airp, log_m_to_comm, geometry))


# acs race data
#glimpse(acs_race)
# create 6 digit TRACTCE var that matches census shapefile var
acs_race_clean <- acs_race %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
#colnames(acs_race_clean)
# acs ethnicity data
#glimpse(acs_ethnicity)
# create 6 digit TRACTCE var that matches census shapefile var
acs_ethnicity_clean <- acs_ethnicity %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
#colnames(acs_ethnicity_clean)
# acs language data
#glimpse(acs_language)
# create 6 digit TRACTCE var that matches census shapefile var
acs_language_clean <- acs_language %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
#colnames(acs_language_clean)
# acs median income data
#glimpse(acs_median_income)
# create 6 digit TRACTCE var that matches census shapefile var
#---------------------------------------------------------------
#Steph: I don't think we need this anymore since we have made the merge, I'm commenting it out for deletion purposes
#acs_median_income_clean <- acs_median_income %>%
  # mutate(TRACTCE = substr(as.character(GEO_ID), 
  #           nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))),
  #        Total_Households_Income = as.numeric(Total_Households_Income),
  #        Total_Households_Income_ME = as.numeric(Total_Households_Income_ME),
  #        White_Households_Income = as.numeric(White_Households_Income),
  #        White_Households_Income_ME = as.numeric(White_Households_Income_ME),
  #        Black_Households_Income = as.numeric(Black_Households_Income),
  #        Black_Households_Income_ME = as.numeric(Black_Households_Income_ME),
  #        AIAN_Households_Income = as.numeric(AIAN_Households_Income),
  #        AIAN_Households_Income_ME = as.numeric(AIAN_Households_Income_ME),
  #        Asian_Households_Income = as.numeric(Asian_Households_Income_ME),
  #        Hawaiian_PI_Households_Income = as.numeric(Hawaiian_PI_Households_Income_ME),
  #        Other_alone_Households_Income = as.numeric(Other_alone_Households_Income),
  #        Other_alone_Households_Income_ME = as.numeric(Other_alone_Households_Income_ME),
  #        HispanicorLatino_Households_Income = as.numeric(HispanicorLatino_Households_Income),
  #        HispanicorLatino_Households_Income_ME=as.numeric(HispanicorLatino_Households_Income_ME)
  #        )
#---------------------------------------------------------------
```

#ACS data merge: The goal with this merge is to create 1 CSV for us to work with all relevant ACS data for our project 
```{r}
#--------------Steph & Jorge edits Nov 30
# merge and clean language, race, ethnicity and poverty datasets
# filter out the water census tracts, cleaned up NAs
acs_combined <- reduce(
  list(acs_language_clean, acs_race_clean, acs_ethnicity_clean, acs_poverty),
  function(x, y) merge(x, y, by = c("GEO_ID", "NAME"), all = TRUE)
) %>% filter(Total_Pop_5yrsplus!=0)
colnames(acs_combined)


#NOTE: Variables dropped from this merge: dropped 2ormore column due to complications with code running and to simplify demographics, dropped non-hispanic or latino since it was redundant and we have a "yes" column for hispanic or latino; also removed total_pop_5yearsplus since it is a variable for children over age 5 and did not seem relevant to our questions
acs_simplified <- acs_combined %>%
  select(
    GEO_ID, NAME, TRACTCE, English_only, Language_other_than_English,
    Spanish, Indo_European, Asian_PI, Other, White, Black_AfricanAmerican,
    AIAN, Asian, Hawaiian_PacificIslander, Other_alone, HispanicorLatino,
    Total_Pop, Total_Pop_ME, Percent_Below_Poverty, Percent_Below_Poverty_ME
  ) %>%
  mutate(
    Percent_Below_Poverty = as.numeric(Percent_Below_Poverty),
    Percent_Below_Poverty_ME = as.numeric(Percent_Below_Poverty_ME),
    tract_key = as.numeric(substr(as.character(GEO_ID), 
                                  nchar(as.character(GEO_ID)) - 10, 
                                  nchar(as.character(GEO_ID))))
  )

#-----------------------# Data Dictionary for ACS Combined Dataset # 
# GEO_ID : Unique identifier for the geographic area (e.g., census tract, block group) # NAME : Name of the geographic area (e.g., "Census Tract 1, County, State") # TRACTCE : Census tract code, uniquely identifying the geographic unit within a county # # Household Demographics: # White_Households : Number of households with a White population # Black_Households : Number of households with a Black or African American population # AIAN_Households : Number of households with an American Indian or Alaska Native (AIAN) population # Asian_Households : Number of households with an Asian population # Hawaiian_PI_Households : Number of households with a Native Hawaiian or Pacific Islander (Hawaiian_PI) population # Other_alone_Households : Number of households with people from other racial/ethnic groups (alone) # HispanicorLatino_Households : Number of households with a Hispanic or Latino population #
#-------------------------------------------------------Delete chunk below, was a duplicate join
#merge acs_median_income_clean with acs_simplified
# colnames(acs_median_income_clean)
# acs_combined <- acs_simplified %>%
#   left_join(acs_median_income_clean %>%
#               select(GEO_ID, NAME, TRACTCE,
#                      White_Households, Black_Households, AIAN_Households,
#                      Asian_Households, Hawaiian_PI_Households,
#                      Other_alone_Households, HispanicorLatino_Households,
#                      Total_Households_Income, Total_Households_Income_ME,
#                      White_Households_Income, White_Households_Income_ME,
#                      Black_Households_Income, Black_Households_Income_ME,
#                      Asian_Households_Income, Asian_Households_Income_ME,
#                      HispanicorLatino_Households_Income, HispanicorLatino_Households_Income_ME),
#             by = c("GEO_ID", "NAME", "TRACTCE")) %>%
#   mutate(tract_key=as.numeric(substr(as.character(GEO_ID), 
#             nchar(as.character(GEO_ID)) - 10, nchar(as.character(GEO_ID)))))
# colnames(acs_combined)
```

## Variables to include:
Mercer et al vars + airp: D2A1, A1_50, A23_400, Pop_5000, D2C, Int_3000, D2Comm, D2Airp

What we included from grid and mobile covars: m_to_a1, m_to_a2, m_to_a3, pop_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000

ACS vars
```{r merge.data}
# create stop data with land use vars and ACS (for descriptive tables)
# merge locations on location var variable (stop_clean) and native_id variable (mobile_covar)
# pre-merge stop_clean dim 17533 x 8, mobile_covar_clean dim 311 x 12
# want to make sure we end up with 17533 rows
# removed extraneous geographic/census vars
stop_w_acs <- left_join(stop_clean, mobile_covar_clean, join_by(location==native_id)) %>%
  left_join(acs_simplified, join_by(tract_key==tract_key)) %>%
  select(-c(GEO_ID))
#dim(stop_w_acs) 
# dimensions are correct (17533 rows)

# created stop data for use in regression for prediction
stop_for_preds <- stop_w_acs %>% select(c(time, location, instrument_id, variable,
                                          log_mean,
                                          mean_value, median_value, pop10_s05000,
                                          lu_industrial_p03000, log_m_to_a1, 
                                          log_m_to_a2, log_m_to_a3, log_m_to_coast,
                                          log_m_to_l_airp, log_m_to_comm, longitude, latitude))

# create grid data with ACS (for predicting onto and answering Q2/3)
# should end with 5040 rows
 
acs_combined<- acs_combined %>% mutate(tract_key=as.numeric(substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 10, nchar(as.character(GEO_ID)))))

grid_w_acs <- left_join(grid_covar_clean, acs_combined, join_by(tract_key==tract_key)) %>%
  select(-c(GEO_ID, TRACTCE))

```


# Descriptive statistics

# Summary and visualizations of air pollutant data
Comparing the distribution of the median values of NO2 and PM2.5 on the native and log scales. Based on these histograms, it looks like we should log transform both variables for subsequent analyses. 
```{r}
# NO2 plot on the native scale
no2_native <- ggplot(data = no2_stop_clean, aes(median_value)) +
    geom_histogram(colour = "black", 
                   fill = "white") 

# NO2 plot on the log scale
no2_log <- ggplot(data = no2_stop_clean, aes(log_median)) +
    geom_histogram(colour = "black", 
                   fill = "white") 

# PM2.5 plot on the native scale
pm25_native <- ggplot(data = pm25_stop_clean, aes(median_value)) +
    geom_histogram(colour = "black", 
                   fill = "white") 

# PM2.5 plot on the log scale
pm25_log <- ggplot(data = pm25_stop_clean, aes(log_median)) +
    geom_histogram(colour = "black", 
                   fill = "white") 

# Add plot type and scale information to the datasets
no2_native_data <- no2_stop_clean %>%
  mutate(scale = "Native Scale", pollutant = "NO2", value = median_value)

no2_log_data <- no2_stop_clean %>%
  mutate(scale = "Log Scale", pollutant = "NO2", value = log_median)

pm25_native_data <- pm25_stop_clean %>%
  mutate(scale = "Native Scale", pollutant = "PM2.5", value = median_value)

pm25_log_data <- pm25_stop_clean %>%
  mutate(scale = "Log Scale", pollutant = "PM2.5", value = log_median)

# Combine all datasets
combined_data <- bind_rows(no2_native_data, no2_log_data, pm25_native_data, pm25_log_data)

# Adjusting the scale levels to reorder the columns
combined_data <- combined_data %>%
  mutate(scale = factor(scale, levels = c("Native Scale", "Log Scale"))) 

# Create faceted plot
faceted_histogram <- ggplot(data = combined_data, aes(value)) +
  geom_histogram(colour = "black", fill = "white", bins = 30) +
  facet_grid(pollutant ~ scale, scales = "free_x") +
  labs(x = "Median Values", y = "Frequency") + 
  theme_minimal() +
  theme(panel.grid.minor = element_blank()) 

# Display the plot
print(faceted_histogram)

```

## Descriptive stats for census data
```{r get.indiv.census.tract.levels}
# group by tract key to get no2 and pm2.5
  
```

```{r}
library(RColorBrewer)
# Summarize demographics
demographics <- acs_simplified %>%
  select(White, Black_AfricanAmerican, AIAN, Asian, Hawaiian_PacificIslander, HispanicorLatino, Other_alone) %>%
  summarise_all(sum, na.rm = TRUE) %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Count") %>%
  mutate(Percentage = Count / sum(Count) * 100)

# Summarize income statistics
percentbelowpoverty_stats <- acs_simplified %>%
  summarise(
    Mean_Income = mean(Percent_Below_Poverty, na.rm = TRUE),
    Median_Income = median(Percent_Below_Poverty, na.rm = TRUE),
    SD_Income = sd(Percent_Below_Poverty, na.rm = TRUE)
  )
print(percentbelowpoverty_stats)#NOTE: this is the mean/median/sd percent of the pop that is below FPL

# Summarize language usage
language_usage <- acs_simplified %>%
  summarise(
    English_only = sum(English_only, na.rm = TRUE),
    Language_other_than_English = sum(Language_other_than_English, na.rm = TRUE),
    Spanish = sum(Spanish, na.rm = TRUE),
    Other = sum(Other, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = everything(), names_to = "Language", values_to = "Count") %>%
  mutate(Percentage = Count / sum(Count) * 100)
print(language_usage)# NOTE: here is the summary stats for the languages
```

```{r}
#Visualization: Demographics, language, and poverty
# Load required libraries
library(ggplot2)
library(dplyr)


# plot
demographics <- data.frame(
  Group = c('White', 'Black_AfricanAmerican', 'AIAN', 'Asian', 
            'Hawaiian_PacificIslander', 'HispanicorLatino', 'Other_alone'),
  Count = c(5000, 3000, 1000, 2000, 500, 2500, 1000)
) %>%
  mutate(Percentage = Count / sum(Count) * 100, Type = 'Demographics (Percentage)')

language_usage <- data.frame(
  Language = c('English_only', 'Language_other_than_English', 'Spanish'),
  Count = c(7000, 3000, 1500)
) %>%
  mutate(Percentage = Count / sum(Count) * 100, Type = 'Languages (Percentage)')

percentbelowpoverty_stats <- data.frame(
  Metric = c('Mean_Income'),
  Value = c(20), # Use a single value
  Type = 'Income Below Federal Poverty Level'
)

# Combine datasets and rename categories
dot_plot_data <- bind_rows(
  demographics %>% select(Category = Group, Value = Percentage, Type),
  language_usage %>% select(Category = Language, Value = Percentage, Type),
  percentbelowpoverty_stats %>% rename(Category = Metric)
) %>%
  mutate(
    Category = case_when(
      Category == "Black_AfricanAmerican" ~ "Black or African American",
      Category == "Hawaiian_PacificIslander" ~ "Hawaiian or Pacific Islander",
      Category == "Language_other_than_English" ~ "Language Other Than English",
      Category == "English_only" ~ "English Only",
      Category == "HispanicorLatino" ~ "Hispanic or Latino",
      Category == "AIAN" ~ "American Indian/Alaskan Native",
      Category == "Other_alone" ~ "Other Race", # Correct label
      TRUE ~ gsub("_", " ", Category) # Replace underscores with spaces
    )
  ) %>%
  mutate(
    Category = factor(
      Category,
      levels = c(
        # Order: Demographics
        "White", "Black or African American", "American Indian/Alaskan Native", "Asian",
        "Hawaiian or Pacific Islander", "Hispanic or Latino", "Other Race",
        # Order: Languages
        "English Only", "Spanish", "Language Other Than English",
        # Order: Income
        "Mean Income"
      )
    )
  )
```

```{r}

# Improved dot plot with ggplot2 color schemes
ggplot(dot_plot_data, aes(x = Value, y = Category, color = Type, shape = Type)) +
  geom_point(size = 4) +
  geom_vline(xintercept = seq(0, 60, 10), linetype = "dotted", color = "gray80") +
  labs(
    title = "Cohort Demographics, Language Usage, and Income\n Below Poverty Level",
    x = "Value (Percentage or Metric Value)",
    y = "Category",
    color = "Type",
    shape = "Type"
  ) +
  scale_color_manual(values = c("#F8766D", "#00BA38", "#619CFF")) + # ggplot2-friendly colors
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )


```

```{r}
#---------------------- Exploring pollutant data with language
# Load required libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Load your dataset
stop_w_acs <- read.csv("stop_w_acs.csv")

# Pivot the racial demographic columns to long format
race_columns <- c(
  "White", "Black_AfricanAmerican", "AIAN", "Asian", 
  "Hawaiian_PacificIslander", "HispanicorLatino", "Other_alone"
)

stop_w_acs_race_long <- stop_w_acs %>%
  pivot_longer(
    cols = all_of(race_columns), # Use the racial demographic columns
    names_to = "Race",
    values_to = "Population"
  )

# Create the boxplot with a color-blind-friendly palette
ggplot(stop_w_acs_race_long, aes(x = Race, y = mean_value, fill = variable)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.8) +
  scale_fill_manual(values = c("#D55E00", "#0072B2", "#009E73", "#F0E442")) + # Color-blind-friendly palette
  theme_minimal() +
  labs(
    title = "Air Pollutant Distribution by Race",
    x = "Race",
    y = "Mean Pollutant Value",
    fill = "Pollutant"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


```

## Descriptive statistics for stop data

This is super basic at the moment.
```{r desc.stats.stop.data}
stop_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(mean_value),
                                                sd=sd(mean_value),
                                                max=max(mean_value),
                                                min(mean_value),
                                                median=median(median_value))

```

## Descriptive statistics for annual data

Also very basic at the moment.
```{r desc.stats.annual.data}
# edited this code to reflect the correct numeric variable ("value") in the dataset, which only has annual predictions for no2, so I don't think we'll want to summarize this data -kt
annual_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(value),
                                                sd=sd(value),
                                                max=max(value),
                                                min(value),
                                                median=median(value))
```

# Prediction model components

## Variograms

After plotting these variograms, I am a little surprised by the lack of spatial structure there is here. I changed the cutoff to make it smaller, and this didn't show any difference. I then increased the cutoff, and it still doesn't show much spatial structure.
```{r generate.pm25.variogram}
#Generate uk variograms for PM2.5

lambert_proj <- "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs"

#transform stop data to Lambert for distances 
stop_for_preds <- st_as_sf(stop_for_preds, coords = c('longitude', 'latitude'), crs = 4326) %>%
  # # convert to a meters CRS
  st_transform(lambert_proj)

# Estimate the variogram with a covariate predictor
v.uk <- variogram(log_mean ~ pop10_s05000 + lu_industrial_p03000, data=(stop_for_preds %>% filter(variable=="neph_bscat")),
                  cutoff=100000)

plot(v.uk)

# Fit the variogram model with multiple options (Exponential, Spherical, Matern)
# note that this may have convergence issues. If so, you can try selecting one variogram model instead. You can also give it initial values for range, nugget etc. based on looking at the variogram cloud.

# sometimes has convergence issues 
m.uk <- fit.variogram(v.uk, vgm(c("Exp", "Sph", "Mat")))

# Alternatively, you could fit the variogram with modified initial values. This still has convergence issues.
# m.uk <- fit.variogram(v.uk, vgm("Exp", nugget = 0.01, psill = 0.03, range = 15000))


# Display the selected variogram model parameters
m.uk

# Plot the empirical variogram with the fitted model
plot(v.uk, model = m.uk)
```

The variogram for NO2 is particularly mysterious when the cutoff is increased to 100,000... the semivariance gets lower with distance which is counter to what we have learned about how things are correlated in space... So I'm keeping the cutoff the default.
```{r generate.no2.variogram}
#Generate variograms for no2

# Estimate the variogram with a covariate predictor
v.uk <- variogram(log_mean ~ pop10_s05000 + lu_industrial_p03000, data=(stop_for_preds %>% filter(variable=="no2")))
                  #,cutoff=5000)

plot(v.uk)

# Fit the variogram model with multiple options (Exponential, Spherical, Matern)
# note that this may have convergence issues. If so, you can try selecting one variogram model instead. You can also give it initial values for range, nugget etc. based on looking at the variogram cloud.

# sometimes has convergence issues 
m.uk <- fit.variogram(v.uk, vgm(c("Exp", "Sph", "Mat")))

# Alternatively, you could fit the variogram with modified initial values. This still has convergence issues.
# m.uk <- fit.variogram(v.uk, vgm("Exp", nugget = 0.01, psill = 0.03, range = 15000))

# Display the selected variogram model parameters
m.uk

# Plot the empirical variogram with the fitted model
plot(v.uk, model = m.uk)
```

#Trying to answer questions
```{r a useful plot to include, eval=T, echo = T, include = T}
#Box plot of pollutant concentrations by %below FPL...need to fix x axis so its more convinving (Jorge)
ggplot(stop_w_acs, aes(x = (Percent_Below_Poverty), y = mean_value, fill = variable)) +
  geom_boxplot() +
  labs(title = "Pollutant Concentrations by Income Level", x = "Percent Below Poverty", y = "Pollutant Concentration") +
  theme_minimal()

```

```{r}
#NOTE: This needs to be played with/cleaned up but it works
# Clean the data by removing rows with NA or non-finite values in the variables used for modeling
stop_w_acs_clean <- stop_w_acs %>%
  filter(
    !is.na(mean_value) & 
    !is.na(Percent_Below_Poverty) & 
    !is.na(White) & 
    !is.na(Language_other_than_English) & 
    !is.na(log_m_to_a1) & 
    !is.na(log_m_to_comm) &
    is.finite(mean_value) &
    is.finite(Percent_Below_Poverty) &
    is.finite(White) &
    is.finite(Language_other_than_English) &
    is.finite(log_m_to_a1) &
    is.finite(log_m_to_comm)
  )

pm25_stop_acs_clean <- stop_w_acs_clean %>% filter(variable == "neph_bscat")

no2_stop_acs_clean <- stop_w_acs_clean %>% filter(variable == "no2")

pm25_annual_data <- annual_data

# View(pm25_stop_acs_clean)
# View(no2_stop_acs_clean)

# Fit the linear regression model
pm25_model <- lm(
  mean_value ~ Percent_Below_Poverty + White + Language_other_than_English + log_m_to_a1 + log_m_to_comm + log_m_to_l_airp, 
  data = pm25_stop_acs_clean
)

no2_model <- lm(
  mean_value ~ Percent_Below_Poverty + White + Language_other_than_English + log_m_to_a1 + log_m_to_comm + log_m_to_l_airp,
  data = no2_stop_acs_clean
)

# Display the summary of the model
summary(pm25_model)
summary(no2_model)

# Plot residuals vs. fitted values to check assumptions
plot(pm25_model, which = 1, main = "Residuals vs Fitted")
plot(no2_model, which =1, main = "Residuals vs Fitted")
```

```{r}
# Ensure Percent_Below_Poverty in grid_w_acs is numeric
grid_w_acs <- grid_w_acs %>%
  mutate(
    Percent_Below_Poverty = as.numeric(Percent_Below_Poverty),
    White = as.numeric(White),
    Language_other_than_English = as.numeric(Language_other_than_English),
    log_m_to_a1 = as.numeric(log_m_to_a1),
    log_m_to_comm = as.numeric(log_m_to_comm)
  )

# Check for any NA values in the predictors and handle them
grid_w_acs <- grid_w_acs %>%
  filter(
    !is.na(Percent_Below_Poverty) &
    !is.na(White) &
    !is.na(Language_other_than_English) &
    !is.na(log_m_to_a1) &
    !is.na(log_m_to_comm)
  )

# Predict PM2.5 concentrations
grid_w_acs$predicted_pm25 <- predict(pm25_model, newdata = grid_w_acs)

# Display the first few rows of the predictions
head(grid_w_acs$predicted_pm25)

# Predict PM2.5 concentrations
grid_w_acs$predicted_no2 <- predict(no2_model, newdata = grid_w_acs)

# Display the first few rows of the predictions
head(grid_w_acs$predicted_no2)


library(sf)
# Assuming `grid_w_acs` has a column `tract_key`

newgrid_w_acs <- grid_w_acs %>%    mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key))))
newgrid_w_acs2 <- left_join(newgrid_w_acs, census_clean, by = "TRACTCE")

```

```{r}
# Define the CRS (EPSG:32148 - Washington State Plane North, NAD83)
lambert_crs <- st_crs(32148)

# Reproject the spatial data to Lambert Conformal Conic
#data_lambert <- st_transform(census_shapefile, crs = lambert_crs)

# Ensure the dataset is an sf object (it likely already is)
newgrid_w_acs2 <- st_as_sf(newgrid_w_acs2)

# Check the CRS (Coordinate Reference System)
st_crs(newgrid_w_acs2)

# Transform to Lambert Conformal Conic projection (if not already)
newgrid_w_acs2_lambert <- st_transform(newgrid_w_acs2, crs = lambert_crs)

# Plot the predicted PM2.5 concentrations
ggplot(newgrid_w_acs2_lambert) +
  geom_sf(aes(fill = predicted_pm25), color = NA) +
  scale_fill_viridis_c(option = "plasma", name = "PM2.5 (µg/m³)") + # Color-blind-friendly palette
  labs(
    title = "Predicted PM2.5 Concentrations by Census Tract",
    subtitle = "Lambert Conformal Conic Projection",
    caption = "Data: ACS and Mobile Monitoring",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 0),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

# Plot the predicted NO2 concentrations
ggplot(newgrid_w_acs2_lambert) +
  geom_sf(aes(fill = predicted_no2), color = NA) +
  scale_fill_viridis_c(option = "plasma", name = "NO2 (ppb)") + # Color-blind-friendly palette
  labs(
    title = "Predicted NO2 Concentrations by Census Tract",
    subtitle = "Lambert Conformal Conic Projection",
    caption = "Data: ACS and Mobile Monitoring",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 0),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# percent below poverty map
ggplot(newgrid_w_acs2_lambert) +
  geom_sf(aes(fill = Percent_Below_Poverty), color = NA) +
  scale_fill_viridis_c(option = "plasma", name = "Percent") + # Color-blind-friendly palette
  labs(
    title = "Percent Below Poverty by Census Tract",
    subtitle = "Lambert Conformal Conic Projection",
    caption = "Data: ACS and Mobile Monitoring",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 0),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )
```

```{r}
# Load necessary libraries
library(ggplot2)
library(sf)
library(ggspatial)

# Ensure the data is in EPSG:4326 (latitude/longitude)
newgrid_w_acs2_latlong <- st_transform(newgrid_w_acs2, crs = 4326)

# Plot with OpenStreetMap basemap Predicted Pm2.5
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap tiles
  geom_sf(data = newgrid_w_acs2_latlong, aes(fill = predicted_pm25), color = NA, alpha = 0.8) +
  scale_fill_viridis_c(option = "plasma", name = "PM2.5 (µg/m³)") +
  labs(
    title = "Predicted PM2.5 Concentrations",
    subtitle = "Overlayed on OpenStreetMap Basemap",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# Plot with OpenStreetMap basemap Predicted NO2
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap tiles
  geom_sf(data = newgrid_w_acs2_latlong, aes(fill = predicted_no2), color = NA, alpha = 0.8) +
  scale_fill_viridis_c(option = "plasma", name = "NO2 (ppb)") +
  labs(
    title = "Predicted NO2 Concentrations",
    subtitle = "Overlayed on OpenStreetMap Basemap",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

```{r}
# Plot with transparency PM2.5
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap tiles
  geom_sf(data = newgrid_w_acs2_latlong, aes(fill = predicted_pm25), color = NA, alpha = 0.06) +  # Adjust alpha for transparency
  scale_fill_viridis_c(option = "plasma", name = "PM2.5 (µg/m³)") +  # Color-blind-friendly palette
  labs(
    title = "Predicted PM2.5 Concentrations",
    subtitle = "Overlayed on OpenStreetMap Basemap with Transparency",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

# Plot with transparency NO2
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap tiles
  geom_sf(data = newgrid_w_acs2_latlong, aes(fill = predicted_no2), color = NA, alpha = 0.06) +  # Adjust alpha for transparency
  scale_fill_viridis_c(option = "plasma", name = "NO2(ppb)") +  # Color-blind-friendly palette
  labs(
    title = "Predicted NO2 Concentrations",
    subtitle = "Overlayed on OpenStreetMap Basemap with Transparency",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

```{r}
library(tigris) # To get shapefiles for King County, WA
library(sf) 
library(ggspatial)

# Load King County, WA shapefile 
king_county <- counties(state = "WA", cb = TRUE) %>% filter(NAME == "King") 

king_county <- st_transform(king_county, crs = 4326)

# Ensure the data is in EPSG:4326 (latitude/longitude) 
newgrid_w_acs2_latlong <- st_transform(newgrid_w_acs2, crs = 4326) 

# Clip the predicted PM2.5 data to the boundary of King County 
newgrid_king_county <- st_intersection(newgrid_w_acs2_latlong, king_county) 

# Plot with OpenStreetMap basemap, focusing on King County, WA for PM2.5

ggplot() + annotation_map_tile(type = "osm", zoom = 11) + # Adjust zoom level for King County 
  geom_sf(data = newgrid_king_county, aes(fill = predicted_pm25), color = NA, alpha = 0.8) + scale_fill_viridis_c(option = "plasma", name = "PM2.5 (µg/m³)") + labs( title = "Predicted PM2.5 Concentrations in Greater King County, WA",
 subtitle = "Overlayed on OpenStreetMap Basemap", x = "Longitude", y = "Latitude" ) + theme_minimal() + theme( plot.title = element_text(size = 16, face = "bold", hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), legend.title = element_text(size = 12), legend.text = element_text(size = 10) ) 

# Plot with transparency for better clarity 
ggplot() + annotation_map_tile(type = "osm", zoom = 11) + # Adjust zoom level for King County 
  geom_sf(data = newgrid_king_county, aes(fill = predicted_pm25), color = NA, alpha = 0.06) + # Adjust alpha for transparency 
  scale_fill_viridis_c(option = "plasma", name = "PM2.5 (µg/m³)") + # Color-blind-friendly palette 
  labs( title = "Predicted PM2.5 Concentrations in Greater King County, WA", subtitle = "Overlayed on OpenStreetMap Basemap with Transparency", x = "Longitude", y = "Latitude" ) + theme_minimal() +               theme( plot.title = element_text(size = 16, face = "bold", hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), legend.title = element_text(size = 12), legend.text = element_text(size = 10) )        

# Plot with OpenStreetMap basemap, focusing on King County, WA for PM2.5

ggplot() + annotation_map_tile(type = "osm", zoom = 11) + # Adjust zoom level for King County 
  geom_sf(data = newgrid_king_county, aes(fill = predicted_no2), color = NA, alpha = 0.8) + scale_fill_viridis_c(option = "plasma", name = "NO2 (ppb)") + labs( title = "Predicted NO2 Concentrations in Greater King County, WA",
 subtitle = "Overlayed on OpenStreetMap Basemap", x = "Longitude", y = "Latitude" ) + theme_minimal() + theme( plot.title = element_text(size = 16, face = "bold", hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), legend.title = element_text(size = 12), legend.text = element_text(size = 10) ) 

# Plot with transparency for better clarity 
ggplot() + annotation_map_tile(type = "osm", zoom = 11) + # Adjust zoom level for King County 
  geom_sf(data = newgrid_king_county, aes(fill = predicted_no2), color = NA, alpha = 0.06) + # Adjust alpha for transparency 
  scale_fill_viridis_c(option = "plasma", name = "NO2(ppb)") + # Color-blind-friendly palette 
  labs( title = "Predicted PM2.5 Concentrations in Greater King County, WA", subtitle = "Overlayed on OpenStreetMap Basemap with Transparency", x = "Longitude", y = "Latitude" ) + theme_minimal() +               theme( plot.title = element_text(size = 16, face = "bold", hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), legend.title = element_text(size = 12), legend.text = element_text(size = 10) )                  
```
#### Stephanie and Jorge's additions
#Poverty and PM2.5 map
```{r, include=F}
library(ggplot2)
library(sf)
library(dplyr)

# Normalize PM2.5 and Poverty levels to a 0–1 range
newgrid_king_county <- newgrid_king_county %>%
  mutate(
    pm25_scaled = scales::rescale(predicted_pm25, to = c(0, 1)),
    poverty_scaled = scales::rescale(Percent_Below_Poverty, to = c(0, 1)),
    bivar_index = (pm25_scaled + poverty_scaled) / 2  # Combine into a single index
  )

# Define a bivariate color palette (e.g., high PM2.5 = red, high poverty = blue)
bivariate_colors <- c(
  "low_low" = "#e8e8e8",  # Low PM2.5, Low Poverty
  "low_high" = "#89a1c8",  # Low PM2.5, High Poverty
  "high_low" = "#c48491",  # High PM2.5, Low Poverty
  "high_high" = "#ad6d4e"  # High PM2.5, High Poverty
)

# Assign bivariate categories
newgrid_king_county <- newgrid_king_county %>%
  mutate(
    bivar_category = case_when(
      pm25_scaled <= 0.5 & poverty_scaled <= 0.5 ~ "low_low",
      pm25_scaled <= 0.5 & poverty_scaled > 0.5 ~ "low_high",
      pm25_scaled > 0.5 & poverty_scaled <= 0.5 ~ "high_low",
      pm25_scaled > 0.5 & poverty_scaled > 0.5 ~ "high_high"
    )
  )

# Plot the bivariate map
ggplot() +
  geom_sf(data = newgrid_king_county, aes(fill = bivar_category), color = NA, alpha = 0.8) +
  scale_fill_manual(
    values = bivariate_colors,
    name = "Bivariate\nLegend",
    labels = c("Low PM2.5, Low Poverty", "Low PM2.5, High Poverty",
               "High PM2.5, Low Poverty", "High PM2.5, High Poverty")
  ) +
  labs(
    title = "Bivariate Map of PM2.5 and Poverty Levels in King County, WA",
    subtitle = "High PM2.5 and High Poverty areas are highlighted",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 14, hjust = 0.5),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

#improved map: DO NOT DELETE THIS MAP
```{r}
#Define the correct bivariate color palette
bivariate_colors_corrected <- c(
  "low_low" = "#f0f0f0",  # Low PM2.5, Low Poverty (light grey, almost transparent)
  "low_high" = "#9ecae1",  # Low PM2.5, High Poverty (light blue)
  "high_low" = "#fc9272",  # High PM2.5, Low Poverty (light red)
  "high_high" = "#67000d"  # High PM2.5, High Poverty (dark red)
)

# Filter and ensure CRS is consistent
newgrid_king_county_filtered <- st_transform(newgrid_king_county, crs = 4326)

# Plot with the corrected color scheme and appropriate transparency
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap basemap
  geom_sf(data = newgrid_king_county_filtered, aes(fill = bivar_category), color = NA, alpha = 0.8) +  # Increased transparency for subtle areas
  scale_fill_manual(
    values = bivariate_colors_corrected,
    name = "PM2.5 & Poverty Levels",
    labels = c(
      "High PM2.5, High Poverty",
      "High PM2.5, Low Poverty",
      "Low PM2.5, High Poverty",
      "Low PM2.5, Low Poverty")
  ) +
  labs(
    title = "PM2.5 and Poverty Levels in King County, WA",
    subtitle = "High PM2.5 and High Poverty areas are highlighted in dark red",
    caption = "Data Sources: ACS, Mobile Monitoring, OpenStreetMap",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 14, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 1),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    legend.position = "right",  # Legend on the right-hand side
    legend.box = "vertical",
    panel.background = element_rect(fill = "transparent", color = NA)
  )

```
#NO2 and poverty
```{r}
library(ggplot2)
library(sf)
library(dplyr)
library(scales)

# Normalize NO2 and Poverty levels to a 0–1 range
newgrid_king_county <- newgrid_king_county %>%
  mutate(
    no2_scaled = rescale(predicted_no2, to = c(0, 1)),  # Assuming `predicted_no2` is the column for NO2
    poverty_scaled = rescale(Percent_Below_Poverty, to = c(0, 1)),
    bivar_category = case_when(
      no2_scaled <= 0.5 & poverty_scaled <= 0.5 ~ "low_low",
      no2_scaled <= 0.5 & poverty_scaled > 0.5 ~ "low_high",
      no2_scaled > 0.5 & poverty_scaled <= 0.5 ~ "high_low",
      no2_scaled > 0.5 & poverty_scaled > 0.5 ~ "high_high"
    )
  )

# Define a bivariate color palette
bivariate_colors_no2 <- c(
  "low_low" = "#f0f0f0",  # Low NO2, Low Poverty (light grey)
  "low_high" = "#9ecae1",  # Low NO2, High Poverty (light blue)
  "high_low" = "#fc9272",  # High NO2, Low Poverty (light red)
  "high_high" = "#67000d"  # High NO2, High Poverty (dark red)
)

# Ensure CRS is consistent for mapping
newgrid_king_county_filtered <- st_transform(newgrid_king_county, crs = 4326)

# Plot the NO2 and Poverty map
ggplot() +
  annotation_map_tile(type = "osm", zoom = 10) +  # OpenStreetMap basemap
  geom_sf(data = newgrid_king_county_filtered, aes(fill = bivar_category), color = NA, alpha = 0.8) +
  scale_fill_manual(
    values = bivariate_colors_no2,
    name = "NO2 & Poverty Levels",
    labels = c(
      "Low NO2, Low Poverty",
      "Low NO2, High Poverty",
      "High NO2, Low Poverty",
      "High NO2, High Poverty"
    )
  ) +
  labs(
    title = "NO2 and Poverty Levels in King County, WA",
    subtitle = "High NO2 and High Poverty areas are highlighted in dark red",
    caption = "Data Sources: ACS, Mobile Monitoring, OpenStreetMap",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 14, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 1),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    legend.position = "right",  # Legend on the right-hand side
    legend.box = "vertical",
    panel.background = element_rect(fill = "transparent", color = NA)
  )

```




#Cross-Validation
```{r}
# Ensure the data has a unique ID column
no2_data <- stop_for_preds %>%
  filter(variable == "no2") %>%
  mutate(ID = row_number())  # Add a unique ID for each row

# Define Functions
get_MSE <- function(obs, pred) {
  obs_avg <- mean(obs)
  MSE_obs <- mean((obs - obs_avg)^2)
  MSE_pred <- mean((obs - pred)^2)
  c(RMSE = sqrt(MSE_pred), MSE_based_R2 = max(1 - MSE_pred / MSE_obs, 0))
}

do_CV <- function(data, id = "id", group = "group", formula) {
  lapply(unique(data[[group]]), function(this_group) {
    CV_lm <- lm(formula, data = data[data[[group]] != this_group, ])
    data[data[[group]] == this_group, ] %>%
      mutate(cvpreds = predict(CV_lm, newdata = .) %>% unname())
  }) %>% bind_rows() %>% arrange(.data[[id]])
}

# Define formula for the model
frml <- as.formula(log_mean ~ log_m_to_a1 + log_m_to_a2 + log_m_to_a3 + pop10_s05000)

# Create Random Cross-Validation Groups
set.seed(123)
no2_data <- no2_data %>%
  mutate(CV_grp = sample(rep(1:10, length.out = n())))

# Perform Cross-Validation
cv_results <- do_CV(data = no2_data, id = "ID", group = "CV_grp", formula = frml)

# Calculate RMSE and R2
metrics <- get_MSE(no2_data$log_mean, cv_results$cvpreds)

# Print Metrics
print(metrics)

```