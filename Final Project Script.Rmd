---
title: "Final Project Script"
output: html_document:
  toc: true
  toc_float: true
  toc_collapsed: true
toc_depth: 3
date: "2024-11-21"
---

# Set-up and load data
```{r setup}
# Clear workspace of all objects and unload non-base packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE)
    )
}

# Load or install 'pacman' for package management
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {
    install.packages("pacman", repos = my_repo)
}

# **SPH server**: need to install rnaturalearthhires like so on the SPH server
if (!require("rnaturalearthhires")) {
    install.packages("rnaturalearthhires", repos = "https://ropensci.r-universe.dev", type = "source")
}

pacman::p_load(
    tidyverse,                 # Data manipulation and visualization
    # takes a while to install on SPH
    ggspatial,                 # Geospatial extensions for ggplot.  
    maptiles, # maptiles and tmap libraries can be used instead of or in combination with ggplot + ggspatial. maptiles offers more tile-based map flexibility; ggspatial provides the ability to annotate maps easily; tmap offers both static and interactive maps that we won't review in this course. 
    terra, # alternative mapping with raster files
    
    # need for SPH server?
    prettymapr,
    
    rnaturalearth,             # Land features for map layers (remove water locations)
    rnaturalearthhires,        # High-resolution land features 
    sf,                        # Handling spatial objects (modern replacement for 'sp')
    knitr,                     # Formatting tables with kable()
    gstat,                     # Geostatistical methods (e.g., kriging)
    Hmisc,                     # Data description functions like describe()
    scales,                    # Color scale customization for ggplot
    akima,                     # Bivariate interpolation for irregular data
    downloader                 # Downloading files over HTTP/HTTPS
)

```

```{r load.data}
getwd()

annual_data <- read_csv("annual_data_and_predictions.csv")

census_shapefile <- st_read("cb_2019_53_tract_500k.shp")

grid_covariates <- read_csv("dr0311_grid_covariates.csv")

mobile_covariates <- read_csv("dr0311_mobile_covariates.csv")

stop_data <- read_csv("stop_data.csv")

```

# Clean data

We selected only NO2 (no2) and PM2.5 (neph_bscat) variables from the stop data and the annual data. We obtained Census shapefile data from the Census Bureau's website for Washington, and only kept those within King, Snohomish, Pierce, and Kitsap counties (*might not need Kitsap but I didn't want to open the map to check*). We linked data using the 6-digit tract code.

Still TO-DO: are we selecting only covariates from Mercer et al? There are currently 887 covariates, we definitely need to pare down, just not sure if we want to add any others.

```{r data.cleaning}
# stop data
colnames(stop_data)
stop_clean <- stop_data %>% 
  filter(variable == "no2" | variable == "neph_bscat") %>%
  select(c(runname, time, location, stop_id, instrument_id, variable, mean_value, median_value))

table(stop_clean$runname)

# annual data
glimpse(annual_data)
table(annual_data$variable)
# keep only NO2 and PM, get rid of annual variable since they are all mean_of_win_medians
annual_clean <- annual_data %>% 
  filter(variable == "no2" | variable == "neph_bscat") %>%
  select(-c(annual))

# census data
glimpse(census_shapefile)
table(census_shapefile$COUNTYFP) # there are 39 counties, we don't need them all 
# only keep King (033), Snohomish (061), Pierce (053), Kitsap (035)
# get rid of LSAD and STATEFP since they are all the same
census_clean <- census_shapefile %>%
  filter(COUNTYFP %in% c("033", "061", "053", "035")) %>%
  select(-c(LSAD,STATEFP))

# grid covar
glimpse(grid_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
grid_covar_clean <- grid_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key)))) 

# mobile covar
glimpse(mobile_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
mobile_covar_clean <- mobile_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key))))
```

# Descriptive statistics

## Descriptive statistics for stop data

This is super basic at the moment.
```{r desc.stats.stop.data}
stop_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(mean_value),
                                                sd=sd(mean_value),
                                                max=max(mean_value),
                                                min(mean_value),
                                                median=median(median_value))

```

## Descriptive statistics for annual data

Also very basic at the moment.
```{r desc.stats.annual.data}
annual_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(mean_value),
                                                sd=sd(mean_value),
                                                max=max(mean_value),
                                                min(mean_value),
                                                median=median(median_value))
```
