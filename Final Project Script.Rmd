---
title: "Final Project Script"
output: html_document:
  toc: true
  toc_float: true
  toc_collapsed: true
toc_depth: 3
date: "2024-11-21"
editor_options: 
  chunk_output_type: console
---

# Set-up and load data
```{r setup}
# Clear workspace of all objects and unload non-base packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE)
    )
}

# Load or install 'pacman' for package management
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {
    install.packages("pacman", repos = my_repo)
}

# **SPH server**: need to install rnaturalearthhires like so on the SPH server
if (!require("rnaturalearthhires")) {
    install.packages("rnaturalearthhires", repos = "https://ropensci.r-universe.dev", type = "source")
}

pacman::p_load(
    tidyverse,                 # Data manipulation and visualization
    # takes a while to install on SPH
    ggspatial,                 # Geospatial extensions for ggplot.  
    maptiles, # maptiles and tmap libraries can be used instead of or in combination with ggplot + ggspatial. maptiles offers more tile-based map flexibility; ggspatial provides the ability to annotate maps easily; tmap offers both static and interactive maps that we won't review in this course. 
    terra, # alternative mapping with raster files
    
    # need for SPH server?
    prettymapr,
    
    rnaturalearth,             # Land features for map layers (remove water locations)
    rnaturalearthhires,        # High-resolution land features 
    sf,                        # Handling spatial objects (modern replacement for 'sp')
    knitr,                     # Formatting tables with kable()
    gstat,                     # Geostatistical methods (e.g., kriging)
    Hmisc,                     # Data description functions like describe()
    scales,                    # Color scale customization for ggplot
    akima,                     # Bivariate interpolation for irregular data
    downloader                 # Downloading files over HTTP/HTTPS
)

```

```{r load.data}
getwd()

annual_data <- read_csv("annual_data_and_predictions.csv")

census_shapefile <- st_read("cb_2019_53_tract_500k.shp")

grid_covariates <- read_csv("dr0311_grid_covariates.csv")

mobile_covariates <- read_csv("dr0311_mobile_covariates.csv")

stop_data <- read_csv("stop_data.csv")

acs_race <- read_csv("ACS19_race.csv")

acs_ethnicity <- read_csv("ACS19_ethnicity.csv")

acs_language <- read_csv("ACS19_language.csv")

acs_median_income <- read_csv("ACS19_median_income.csv")

acs_poverty <- read_csv("ACS19_poverty.csv")
```

# Clean data

We selected only NO2 (no2) and PM2.5 (neph_bscat) variables from the stop data and the annual data. We obtained Census shapefile data from the Census Bureau's website for Washington, and only kept those within King, Snohomish, Pierce, and Kitsap counties (*might not need Kitsap but I didn't want to open the map to check*). We linked data using the 6-digit tract code.

Still TO-DO: are we selecting only covariates from Mercer et al? There are currently 887 covariates, we definitely need to pare down, just not sure if we want to add any others. #Jorge & Stephanie vote to select the 7 covariates from hw + airport?

```{r data.cleaning}
# stop data
colnames(stop_data)
stop_clean <- stop_data %>% 
  filter(variable == "no2" | variable == "neph_bscat") %>%
  select(c(runname, time, location, stop_id, instrument_id, variable, mean_value, median_value))

table(stop_clean$runname)

# annual data
#glimpse(annual_data)
table(annual_data$variable)
# keep only NO2 and PM, get rid of annual variable since they are all mean_of_win_medians
annual_clean <- annual_data %>% 
  filter(variable == "no2" | variable == "neph_bscat") %>%
  select(-c(annual))

# census data
#glimpse(census_shapefile)
table(census_shapefile$COUNTYFP) # there are 39 counties, we don't need them all 
# only keep King (033), Snohomish (061), Pierce (053), Kitsap (035)
# get rid of LSAD and STATEFP since they are all the same
census_clean <- census_shapefile %>%
  filter(COUNTYFP %in% c("033", "061", "053", "035")) %>%
  select(-c(LSAD,STATEFP))

# grid covar
#glimpse(grid_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
# log-transform distance covariates

grid_covar_clean <- grid_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key)))) %>%
  select(c(location_id, native_id, tract_key, m_to_a1, m_to_a2, m_to_a3, pop10_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000)) %>%
  mutate(log_m_to_a1 = log(m_to_a1), log_m_to_a2=log(m_to_a2), log_m_to_a3=log(m_to_a3),
         log_m_to_coast=log(m_to_coast), log_m_to_l_airp=log(m_to_l_airp), 
         log_m_to_comm=log(m_to_comm)) %>% 
  select(-c(m_to_a1,m_to_a2,m_to_a3,m_to_coast,m_to_l_airp,m_to_comm))

# mobile covar
#glimpse(mobile_covariates)
# create 6 digit TRACTCE var that matches census shapefile var
mobile_covar_clean <- mobile_covariates %>%
  mutate(TRACTCE = substr(as.character(tract_key), 
            nchar(as.character(tract_key)) - 5, nchar(as.character(tract_key)))) %>%
  select(c(location_id, native_id, tract_key, m_to_a1, m_to_a2, m_to_a3, pop10_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000)) %>%
  mutate(log_m_to_a1 = log(m_to_a1), log_m_to_a2=log(m_to_a2), log_m_to_a3=log(m_to_a3),
         log_m_to_coast=log(m_to_coast), log_m_to_l_airp=log(m_to_l_airp), 
         log_m_to_comm=log(m_to_comm)) %>% 
  select(-c(m_to_a1,m_to_a2,m_to_a3,m_to_coast,m_to_l_airp,m_to_comm))

# acs race data
#glimpse(acs_race)
# create 6 digit TRACTCE var that matches census shapefile var
acs_race_clean <- acs_race %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
colnames(acs_race_clean)
# acs ethnicity data
#glimpse(acs_ethnicity)
# create 6 digit TRACTCE var that matches census shapefile var
acs_ethnicity_clean <- acs_ethnicity %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
colnames(acs_ethnicity_clean)
# acs language data
#glimpse(acs_language)
# create 6 digit TRACTCE var that matches census shapefile var
acs_language_clean <- acs_language %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))))
colnames(acs_language_clean)
# acs median income data
#glimpse(acs_median_income)
# create 6 digit TRACTCE var that matches census shapefile var
acs_median_income_clean <- acs_median_income %>%
  mutate(TRACTCE = substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 5, nchar(as.character(GEO_ID))),
         Total_Households_Income = as.numeric(Total_Households_Income),
         Total_Households_Income_ME = as.numeric(Total_Households_Income_ME),
         White_Households_Income = as.numeric(White_Households_Income),
         White_Households_Income_ME = as.numeric(White_Households_Income_ME),
         Black_Households_Income = as.numeric(Black_Households_Income),
         Black_Households_Income_ME = as.numeric(Black_Households_Income_ME),
         AIAN_Households_Income = as.numeric(AIAN_Households_Income),
         AIAN_Households_Income_ME = as.numeric(AIAN_Households_Income_ME),
         Asian_Households_Income = as.numeric(Asian_Households_Income_ME),
         Hawaiian_PI_Households_Income = as.numeric(Hawaiian_PI_Households_Income_ME),
         Other_alone_Households_Income = as.numeric(Other_alone_Households_Income),
         Other_alone_Households_Income_ME = as.numeric(Other_alone_Households_Income_ME),
         HispanicorLatino_Households_Income = as.numeric(HispanicorLatino_Households_Income),
         HispanicorLatino_Households_Income_ME=as.numeric(HispanicorLatino_Households_Income_ME)
         )
```

#ACS data merge: The goal with this merge is to create 1 CSV for us to work with all relevant ACS data for our project 
```{r}

#------------------------------------------------steph cleaning: How can we determine if a census tract is above or below FPL using this data?

#Load data frames: acs_language_clean, acs_median_income_clean, acs_race_clean

# Find common column names across all three datasets
common_columns <- Reduce(intersect, list(colnames(acs_language_clean), 
                                         colnames(acs_median_income_clean), 
                                         colnames(acs_race_clean)))


# Print the common columns
print(common_columns)

colnames(acs_language_clean)
colnames(acs_race_clean)
colnames(acs_ethnicity_clean)

# merge and clean language, race, ethnicity datasets
# filter out the water census tracts, cleaned up NAs
acs_combined <- reduce(
  list(acs_language_clean, acs_race_clean, acs_ethnicity_clean, acs_poverty),
  function(x, y) merge(x, y, by = c("GEO_ID", "NAME"), all = TRUE)
) %>% filter(Total_Pop_5yrsplus!=0)
colnames(acs_combined)

#NOTE: Variables dropped from this merge: dropped 2ormore column due to complications with code running and to simplify demographics, dropped non-hispanic or latino since it was redundant and we have a "yes" column for hispanic or latino; also removed total_pop_5yearsplus since it is a variable for children over age 5 and did not seem relevant to our questions
acs_simplified <- acs_combined %>%
  select(GEO_ID, NAME, TRACTCE, English_only, Language_other_than_English, Spanish, Indo_European, Asian_PI, Other, White, Black_AfricanAmerican, AIAN, Asian, Hawaiian_PacificIslander, Other_alone, HispanicorLatino, Total_Pop, Total_Pop_ME, Percent_Below_Poverty, Percent_Below_Poverty_ME)
colnames(acs_simplified)
#-----------------------# Data Dictionary for ACS Combined Dataset # 
# GEO_ID : Unique identifier for the geographic area (e.g., census tract, block group) # NAME : Name of the geographic area (e.g., "Census Tract 1, County, State") # TRACTCE : Census tract code, uniquely identifying the geographic unit within a county # # Household Demographics: # White_Households : Number of households with a White population # Black_Households : Number of households with a Black or African American population # AIAN_Households : Number of households with an American Indian or Alaska Native (AIAN) population # Asian_Households : Number of households with an Asian population # Hawaiian_PI_Households : Number of households with a Native Hawaiian or Pacific Islander (Hawaiian_PI) population # Other_alone_Households : Number of households with people from other racial/ethnic groups (alone) # HispanicorLatino_Households : Number of households with a Hispanic or Latino population #
#----------------------
#merge acs_median_income_clean with acs_simplified
colnames(acs_median_income_clean)
acs_combined <- acs_simplified %>%
  left_join(acs_median_income_clean %>%
              select(GEO_ID, NAME, TRACTCE,
                     White_Households, Black_Households, AIAN_Households,
                     Asian_Households, Hawaiian_PI_Households,
                     Other_alone_Households, HispanicorLatino_Households,
                     Total_Households_Income, Total_Households_Income_ME,
                     White_Households_Income, White_Households_Income_ME,
                     Black_Households_Income, Black_Households_Income_ME,
                     Asian_Households_Income, Asian_Households_Income_ME,
                     HispanicorLatino_Households_Income, HispanicorLatino_Households_Income_ME),
            by = c("GEO_ID", "NAME", "TRACTCE")) %>%
  mutate(tract_key=as.numeric(substr(as.character(GEO_ID), 
            nchar(as.character(GEO_ID)) - 10, nchar(as.character(GEO_ID)))))
colnames(acs_combined)
```

## Variables to include:
Mercer et al vars + airp: D2A1, A1_50, A23_400, Pop_5000, D2C, Int_3000, D2Comm, D2Airp

What we included from grid and mobile covars: m_to_a1, m_to_a2, m_to_a3, pop_s05000, m_to_coast, m_to_l_airp, m_to_comm,lu_industrial_p03000

ACS vars
```{r merge.data}
# create stop data with land use vars and ACS (for descriptive tables)
# merge locations on location var variable (stop_clean) and native_id variable (mobile_covar)
# pre-merge stop_clean dim 17533 x 8, mobile_covar_clean dim 311 x 12
# want to make sure we end up with 17533 rows
# removed extraneous geographic/census vars
stop_w_acs <- left_join(stop_clean, mobile_covar_clean, join_by(location==native_id)) %>%
  left_join(acs_combined, join_by(tract_key==tract_key)) %>%
  select(-c(GEO_ID, TRACTCE))
dim(stop_w_acs) 
# dimensions are correct (17533 rows)

# created stop data for use in regression for prediction
stop_for_preds <- stop_w_acs %>% select(c(time, location, instrument_id, variable,
                                          mean_value, median_value, pop10_s05000,
                                          lu_industrial_p03000, log_m_to_a1, 
                                          log_m_to_a2, log_m_to_a3, log_m_to_coast,
                                          log_m_to_l_airp, log_m_to_comm))

# create grid data with ACS (for predicting onto and answering Q2/3)
# should end with 5040 rows
grid_w_acs <- left_join(grid_covar_clean, acs_combined, join_by(tract_key==tract_key)) %>%
  select(-c(GEO_ID, TRACTCE))

```


# Descriptive statistics

## Descriptive stats for census data
```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(tidyr)

# Summarize demographics
demographics <- acs_combined %>%
  select(White, Black_AfricanAmerican, AIAN, Asian, Hawaiian_PacificIslander, HispanicorLatino, Other_alone) %>%
  summarise_all(sum, na.rm = TRUE) %>%
  pivot_longer(cols = everything(), names_to = "Group", values_to = "Count") %>%
  mutate(Percentage = Count / sum(Count) * 100)

# Summarize income statistics
income_stats <- acs_combined %>%
  summarise(
    Mean_Income = mean(Total_Households_Income, na.rm = TRUE),
    Median_Income = median(Total_Households_Income, na.rm = TRUE),
    SD_Income = sd(Total_Households_Income, na.rm = TRUE)
  )

income_by_group <- acs_combined %>%
  summarise(
    Mean_Income = mean(Total_Households_Income, na.rm = TRUE),
    Median_Income = median(Total_Households_Income, na.rm = TRUE)
  )

# Summarize language usage
language_usage <- acs_combined %>%
  summarise(
    English_only = sum(English_only, na.rm = TRUE),
    Language_other_than_English = sum(Language_other_than_English, na.rm = TRUE),
    Spanish = sum(Spanish, na.rm = TRUE),
    Other = sum(Other, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = everything(), names_to = "Language", values_to = "Count") %>%
  mutate(Percentage = Count / sum(Count) * 100)

# Income by language
income_by_language <- acs_combined %>%
  group_by(Language = case_when(
    !is.na(English_only) ~ "English_only",
    !is.na(Spanish) ~ "Spanish",
    !is.na(Language_other_than_English) ~ "Other"
  )) %>%
  summarise(
    Mean_Income = mean(Total_Households_Income, na.rm = TRUE),
    Median_Income = median(Total_Households_Income, na.rm = TRUE)
  )

# # Summarize above/below FPL
# fpl_summary <- acs_combined %>%
#   group_by(Above_FPL) %>%
#   summarise(
#     Count = n(),
#     Percentage = Count / nrow(acs_data) * 100
#   )
# 
# fpl_by_group <- acs_combined %>%
#   group_by(Group = case_when(
#     !is.na(White) ~ "White",
#     !is.na(Black_AfricanAmerican) ~ "Black_AfricanAmerican",
#     !is.na(HispanicorLatino) ~ "HispanicorLatino"
#   ), Above_FPL) %>%
#   summarise(Count = n(), .groups = "drop") %>%
#   group_by(Group) %>%
#   mutate(Percentage = Count / sum(Count) * 100)

# Visualization: Demographics Bar Chart
ggplot(demographics, aes(x = Group, y = Count, fill = Group)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Racial/Ethnic Composition of Households", x = "Group", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# # Visualization: Income Distribution Box Plot
# #ggplot(acs_combined, aes(x = factor(Above_FPL), y = Total_Households_Income, fill = Above_FPL)) +
#   # geom_boxplot() +
#   theme_minimal() +
#   labs(title = "Income Distribution Above/Below FPL", x = "Above/Below FPL", y = "Total Household Income")

# Print tables for review
print("Demographics Summary")
print(demographics)

print("Income Statistics")
print(income_stats)

print("Language Usage Summary")
print(language_usage)

print("Income by Language")
print(income_by_language)

#print("Above/Below FPL Summary")
#print(fpl_summary)

#print("Above/Below FPL by Group")
#print(fpl_by_group)

```

## Descriptive statistics for stop data

This is super basic at the moment.
```{r desc.stats.stop.data}
stop_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(mean_value),
                                                sd=sd(mean_value),
                                                max=max(mean_value),
                                                min(mean_value),
                                                median=median(median_value))

```

## Descriptive statistics for annual data

Also very basic at the moment.
```{r desc.stats.annual.data}
# edited this code to reflect the correct numeric variable ("value") in the dataset, which only has annual predictions for no2, so I don't think we'll want to summarize this data -kt
annual_clean %>% group_by(variable) %>% summarise(N=n(),
                                                mean=mean(value),
                                                sd=sd(value),
                                                max=max(value),
                                                min(value),
                                                median=median(value))
```
